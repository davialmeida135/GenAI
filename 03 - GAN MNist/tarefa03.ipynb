{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87c5338",
   "metadata": {},
   "source": [
    "# Tarefa:\n",
    "\n",
    "Utilize a base de dados de dígitos MNIST.\n",
    "\n",
    "1. Modifique a arquitetura do gerador base (reduzindo sua capacidade) mantendo o discriminador base.\n",
    "\n",
    "por exemplo\n",
    "- removendo camadas\n",
    "- reduzindo o número de kernels por camada\n",
    "\n",
    "2. Modifique a arquitetura do discriminador base (reduzindo sua capacidade) mantendo o gerador base.\n",
    "\n",
    "por exemplo:\n",
    "- removendo camadas\n",
    "- reduzindo o número de kernels por camada\n",
    "\n",
    "3. Varie as taxas de aprendizado do gerador e do discriminador de forma independente.\n",
    "0.1 -> 0.001 -> 0.00001\n",
    "\n",
    "4. Teste um otimizador adicional (ex.: SGD ou Adam).\n",
    "\n",
    "Mudar os dois para Adam\n",
    "\n",
    "5. Realize a interpolação entre dois vetores latentes.\n",
    "\n",
    "\n",
    "Entregáveis:\n",
    "1. Notebook\n",
    "2. Relatório pdf: **Reporte e comente os resultados no relatório.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96111509",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e921df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccbb64",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x * 2.0 - 1.0),\n",
    "])\n",
    "\n",
    "# Baixa os dados de treinamento a partir de conjuntos de dados públicos\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",             # Diretório onde os dados serão armazenados\n",
    "    train=True,              # Indica que este é o conjunto de dados de treinamento\n",
    "    download=True,           # Baixa os dados automaticamente, caso ainda não estejam presentes\n",
    "    transform=transform,    # Aplica a transformação ToTensor para converter as imagens em tensores\n",
    ")\n",
    "\n",
    "# Baixa os dados de teste a partir de conjuntos de dados públicos\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",             # Diretório onde os dados serão armazenados\n",
    "    train=False,             # Indica que este é o conjunto de dados de teste\n",
    "    download=True,           # Baixa os dados automaticamente, caso ainda não estejam presentes\n",
    "    transform=transform,     # Aplica a transformação ToTensor para converter as imagens em tensores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8068ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X [N, C, H, W]: torch.Size([32, 1, 28, 28]), Tipo de dados em X: torch.float32\n",
      "Forma de y [N, ] : torch.Size([32]), Tipo de dados em y: torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32                                                                                     # Define o tamanho do lote\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, drop_last=True)   # Cria o DataLoader para o conjunto de treinamento\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)                                      # Cria o DataLoader para o conjunto de teste\n",
    "\n",
    "# Itera sobre o DataLoader de teste para visualizar as formas dos dados\n",
    "for X, y in test_dataloader:\n",
    "    # Exibe a forma e o tipo do tensor de imagens\n",
    "    # N = tamanho do lote, C = canais (1 para imagens em tons de cinza), H = altura, W = largura\n",
    "    print(f\"Forma de X [N, C, H, W]: {X.shape}, Tipo de dados em X: {X.dtype}\")\n",
    "\n",
    "    # Exibe a forma e o tipo dos rótulos (labels)\n",
    "    print(f\"Forma de y [N, ] : {y.shape}, Tipo de dados em y: {y.dtype}\")\n",
    "\n",
    "    break  # Encerra o loop após a primeira iteração, apenas para inspeção dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af2133",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1117e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gerador(nn.Module):\n",
    "    def __init__(self, z_dim=100):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 7*7*128),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(128, 7, 7)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b864fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminador(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296ce5c",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b682a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(dataloader, gerador, discriminador, loss_fn, opt_gerador, opt_discriminador, device, epoch, z_dim):\n",
    "    gerador.train()         # Coloca o modelo em modo de treinamento (ativa dropout, batchnorm, etc., se houver)\n",
    "    discriminador.train()   # Coloca o modelo em modo de treinamento (ativa dropout, batchnorm, etc., se houver)\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (real_data, _) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = real_data.shape[0]\n",
    "        real_data = real_data.to(device)\n",
    "\n",
    "        # ========================================\n",
    "        # Treinamento do DISCRIMINADOR\n",
    "        # ========================================\n",
    "\n",
    "        # Gera rótulos para dados reais (1) e falsos (0)\n",
    "        labels_reais = torch.ones((batch_size, 1), device=device)\n",
    "        labels_falsos = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "        # Gera dados falsos a partir de ruído aleatório (distribuicão normal)\n",
    "        z = torch.randn((batch_size, z_dim), device=device)\n",
    "        dados_falsos = gerador(z)\n",
    "\n",
    "        # Calcula a saída do discriminador para dados reais e falsos\n",
    "        saida_reais = discriminador(real_data)\n",
    "        saida_falsos = discriminador(dados_falsos.detach())  # detach() evita que os gradientes fluam para o gerador\n",
    "\n",
    "        # Calcula a perda do discriminador\n",
    "        perda_reais = loss_fn(saida_reais, labels_reais)\n",
    "        perda_falsos = loss_fn(saida_falsos, labels_falsos)\n",
    "        perda_discriminador = perda_reais + perda_falsos\n",
    "\n",
    "        # Atualiza o discriminador\n",
    "        opt_discriminador.zero_grad()\n",
    "        perda_discriminador.backward()\n",
    "        opt_discriminador.step()\n",
    "\n",
    "        # ========================================\n",
    "        # Treinamento do GERADOR\n",
    "        # ========================================\n",
    "\n",
    "        # Gera novos vetores latentes\n",
    "        z = torch.randn((batch_size, z_dim), device=device)\n",
    "        dados_falsos = gerador(z)\n",
    "\n",
    "        # Queremos que o discriminador pense que os dados falsos são reais\n",
    "        saida_falsos = discriminador(dados_falsos)\n",
    "        perda_gerador = loss_fn(saida_falsos, labels_reais)  # usamos labels_reais aqui!\n",
    "\n",
    "        # Atualiza o gerador\n",
    "        opt_gerador.zero_grad()\n",
    "        perda_gerador.backward()\n",
    "        opt_gerador.step()\n",
    "\n",
    "        # ========================================\n",
    "        # Log de progresso\n",
    "        # ========================================\n",
    "        if batch % 100 == 0 or batch == len(dataloader) - 1:\n",
    "            print(f\"[Época {epoch:03d}] [Lote {batch:03d}/{len(dataloader)}] \"\n",
    "                  f\"Perda D: {perda_discriminador.item():.4f} | Perda G: {perda_gerador.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab97e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função de gerar dados falsos de um vetor latente fixo\n",
    "def gerar(gerador, device, z_dim=100):\n",
    "    gerador.eval()                  # Coloca o modelo em modo de avaliação (desativa dropout, batchnorm, etc.)\n",
    "    # Desativa o cálculo de gradientes para economizar memória e acelerar a execução\n",
    "    with torch.no_grad():\n",
    "      z = torch.zeros((1, z_dim), device=device)\n",
    "      dados_falsos = gerador(z).detach().cpu().numpy().reshape(28,28)\n",
    "    return dados_falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerador(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=6272, bias=True)\n",
      "    (1): Unflatten(dim=1, unflattened_size=(128, 7, 7))\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminador(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=6272, out_features=1, bias=True)\n",
      "    (8): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Usando cpu.\n"
     ]
    }
   ],
   "source": [
    "z_dim = 100\n",
    "# Inicializa os modelos\n",
    "modelo_gerador = Gerador(z_dim)\n",
    "# Imprime a arquitetura do modelo\n",
    "print(modelo_gerador)\n",
    "# Inicializa os modelos\n",
    "modelo_discriminador = Discriminador()\n",
    "# Imprime a arquitetura do modelo\n",
    "print(modelo_discriminador)\n",
    "\n",
    "# Opcional: tenta usar GPU se disponível\n",
    "#device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device=\"cpu\"\n",
    "modelo_gerador.to(device)\n",
    "modelo_discriminador.to(device)\n",
    "\n",
    "# Exibe qual dispositivo está sendo utilizado\n",
    "print(f\"Usando {device}.\")\n",
    "\n",
    "# Otimizadores\n",
    "# VARIAR TODOS ESSES \n",
    "lr_gerador = 1e-3         # taxa de aprendizagem do gerador\n",
    "lr_discriminador = 1e-3   # learning rate do discriminador\n",
    "optimizador_gerador = torch.optim.RMSprop(modelo_gerador.parameters(), lr=lr_gerador)\n",
    "optimizador_discriminador = torch.optim.RMSprop(modelo_discriminador.parameters(), lr=lr_discriminador)\n",
    "\n",
    "# Função de perda\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8fd23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Época 001] [Lote 000/1875] Perda D: 1.3759 | Perda G: 2.2004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m evolução_dado_falso = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoca \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrain_dcgan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgerador\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodelo_gerador\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiscriminador\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodelo_discriminador\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt_gerador\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizador_gerador\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt_discriminador\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizador_discriminador\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz_dim\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoca % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoca == \u001b[32m1\u001b[39m:\n\u001b[32m     16\u001b[39m       evolução_dado_falso.append(gerar(gerador=modelo_gerador, device=device, z_dim=z_dim))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtrain_dcgan\u001b[39m\u001b[34m(dataloader, gerador, discriminador, loss_fn, opt_gerador, opt_discriminador, device, epoch, z_dim)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Atualiza o discriminador\u001b[39;00m\n\u001b[32m     34\u001b[39m opt_discriminador.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mperda_discriminador\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m opt_discriminador.step()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Treinamento do GERADOR\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Gera novos vetores latentes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Define o número total de épocas (iterações completas sobre o conjunto de dados de treinamento)\n",
    "evolução_dado_falso = []\n",
    "for epoca in range(1, num_epochs + 1):\n",
    "    train_dcgan(\n",
    "        dataloader=train_dataloader,\n",
    "        gerador=modelo_gerador,\n",
    "        discriminador=modelo_discriminador,\n",
    "        loss_fn=loss_fn,\n",
    "        opt_gerador=optimizador_gerador,\n",
    "        opt_discriminador=optimizador_discriminador,\n",
    "        device=device,\n",
    "        epoch=epoca,\n",
    "        z_dim=z_dim\n",
    "    )\n",
    "    if epoca % 2 == 0 or epoca == 1:\n",
    "      evolução_dado_falso.append(gerar(gerador=modelo_gerador, device=device, z_dim=z_dim))\n",
    "print(\"Fim!\")  # Exibe mensagem final indicando que o treinamento terminou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b83765",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função de gerar dados falsos de um vetores latentes aleatorios\n",
    "def gerar_aleatorio(gerador, device, z_dim=z_dim, n_images=20):\n",
    "    gerador.eval()                  # Coloca o modelo em modo de avaliação (desativa dropout, batchnorm, etc.)\n",
    "    z = torch.randn((n_images, z_dim), device=device)\n",
    "    # Desativa o cálculo de gradientes para economizar memória e acelerar a execução\n",
    "    with torch.no_grad():\n",
    "      dados_falsos = modelo_gerador(z).detach().cpu().numpy()\n",
    "    return dados_falsos\n",
    "\n",
    "# Função para plotar várias imagens em um grid\n",
    "def plot_multiple_images(imagens, n_cols=7):\n",
    "    n_cols = n_cols\n",
    "    n_rows = (len(imagens) - 1) // n_cols + 1\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, img in enumerate(imagens):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Gera um lote com imagens falsas\n",
    "imagens = gerar_aleatorio(modelo_gerador, device, z_dim=z_dim, n_images=28)\n",
    "\n",
    "# Chama a função para plotar as imagens\n",
    "plot_multiple_images(imagens, n_cols=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b2e25",
   "metadata": {},
   "source": [
    "## Intepolação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que interpola entre dois vetores latentes e gera imagens correspondentes\n",
    "def interpolar_espaco_latente(gerador, z_dim=100, steps=10, device='cpu'):\n",
    "\n",
    "    # Gera dois vetores latentes aleatórios\n",
    "    z1 = torch.randn((1, z_dim), device=device)\n",
    "    z2 = torch.randn((1, z_dim), device=device)\n",
    "\n",
    "    gerador.eval()  # Coloca o gerador em modo de avaliação\n",
    "\n",
    "    alpha_valores = torch.linspace(0, 1, steps).to(device)  # Valores de interpolação entre 0 e 1\n",
    "    imagens_interpoladas = []\n",
    "\n",
    "    for alpha in alpha_valores:\n",
    "        # Interpola linearmente entre z1 e z2: z_interp = (1 - alpha) * z1 + alpha * z2 , alpha em [0, 1]\n",
    "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "\n",
    "        with torch.no_grad():  # Evita calcular gradientes (modo de inferência)\n",
    "            imagem_gerada = gerador(z_interp.to(device)).cpu()\n",
    "\n",
    "        # Remove dimensões extras e converte para numpy\n",
    "        imagens_interpoladas.append(imagem_gerada.squeeze().numpy())\n",
    "\n",
    "    return imagens_interpoladas\n",
    "\n",
    "# Função para plotar uma lista de imagens em uma única linha\n",
    "def plotar_imagens(imagens):\n",
    "    fig, eixos = plt.subplots(1, len(imagens), figsize=(len(imagens), 1.5))\n",
    "    for ax, img in zip(eixos, imagens):\n",
    "        ax.imshow(img.reshape(28, 28), cmap='gray')  # Mostra a imagem em escala de cinza\n",
    "        ax.axis('off')                               # Remove os eixos para visualização limpa\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bca9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera imagens interpoladas entre z1 e z2\n",
    "imagens = interpolar_espaco_latente(modelo_gerador, z_dim=z_dim, steps=20, device=device)\n",
    "\n",
    "# Plota as imagens lado a lado\n",
    "plotar_imagens(imagens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
